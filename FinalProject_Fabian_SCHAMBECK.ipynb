{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ef7e4059c0d4db5a07306d1acbb1477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8bcefe5374646d4a7b48eef63d859e1",
              "IPY_MODEL_d261f83156f3484280dc94f52cbe2b8f",
              "IPY_MODEL_16b70746cd69408197c1a0733d050fb4"
            ],
            "layout": "IPY_MODEL_6fb6de97f190461e922427925c1a898c"
          }
        },
        "f8bcefe5374646d4a7b48eef63d859e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37196bc6f4194ed0b1534d67cc4bb1ef",
            "placeholder": "​",
            "style": "IPY_MODEL_51ff10199c93443db58318e6be1ca744",
            "value": "Map: 100%"
          }
        },
        "d261f83156f3484280dc94f52cbe2b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94fc2ea1ad30407abc010715cab85409",
            "max": 492,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a250dbbe193a446e8751d663c79683f7",
            "value": 492
          }
        },
        "16b70746cd69408197c1a0733d050fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0d21712b5b446e8a2de84dbc4143cda",
            "placeholder": "​",
            "style": "IPY_MODEL_2a30c3ff3811445a9384ba381815f953",
            "value": " 492/492 [00:00&lt;00:00, 6737.66 examples/s]"
          }
        },
        "6fb6de97f190461e922427925c1a898c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37196bc6f4194ed0b1534d67cc4bb1ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51ff10199c93443db58318e6be1ca744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94fc2ea1ad30407abc010715cab85409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a250dbbe193a446e8751d663c79683f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0d21712b5b446e8a2de84dbc4143cda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a30c3ff3811445a9384ba381815f953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fubotz/ICL_2024W/blob/main/FinalProject_Fabian_SCHAMBECK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ICL Final Project: Finetuning a Pretrained Multilingual Model for Cognate Detection\n",
        "\n",
        "Model: xlm-roberta-base\n",
        "\n",
        "Dataset: custom dataset containing en-fr cognates (Frossard et al.)\n",
        "\n",
        "Method: MASK approach"
      ],
      "metadata": {
        "id": "N4_fSCGEAFZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets\n",
        "!pip install -q evaluate\n",
        "!pip install -q transformers\n",
        "!pip install -q torch"
      ],
      "metadata": {
        "id": "v1II96WS0W56"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YwUn733bt7lE",
        "outputId": "a0a5edd4-62e2-483a-864c-506a57b766d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset ##"
      ],
      "metadata": {
        "id": "5HQHtDU0_JW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/fubotz/ICL_2024W/refs/heads/main/word_pairs.json        # dataset taken from Frossard et al."
      ],
      "metadata": {
        "id": "kcC8-tRZ-5yb",
        "outputId": "05ab4f55-6737-4ade-a9fe-fb02cbfd8554",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-05 22:43:47--  https://raw.githubusercontent.com/fubotz/ICL_2024W/refs/heads/main/word_pairs.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23242 (23K) [text/plain]\n",
            "Saving to: ‘word_pairs.json’\n",
            "\n",
            "\rword_pairs.json       0%[                    ]       0  --.-KB/s               \rword_pairs.json     100%[===================>]  22.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-05 22:43:47 (54.7 MB/s) - ‘word_pairs.json’ saved [23242/23242]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"word_pairs.json\", \"r\") as f:\n",
        "    dataset = json.load(f)\n",
        "print(dataset[:10])"
      ],
      "metadata": {
        "id": "JTOGfoFS_MaX",
        "outputId": "c479a029-1fd9-4351-e95b-ec914bc8fde6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'abandon': 'abandon'}, {'abbe': 'abbé'}, {'abdomen': 'abdomen'}, {'abdominal': 'abdominal'}, {'aberration': 'aberration'}, {'abolition': 'abolition'}, {'abominable': 'abominable'}, {'absence': 'absence'}, {'absolute': 'absolu'}, {'absolution': 'absolution'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Convert the dataset to a dictionary format with separate lists for English and French words\n",
        "dataset_dict = {\n",
        "    \"word_en\": [list(pair.keys())[0] for pair in dataset],      # Extract English words\n",
        "    \"word_fr\": [list(pair.values())[0] for pair in dataset]     # Extract French words\n",
        "}\n",
        "\n",
        "# Convert to Hugging Face dataset\n",
        "dataset = Dataset.from_dict(dataset_dict)\n",
        "\n",
        "# Verify structure\n",
        "print(dataset, \"\\n\")\n",
        "print(dataset[:10])"
      ],
      "metadata": {
        "id": "qmP-UoqdJmrn",
        "outputId": "558bfd84-da46-4da5-8e1d-b317f31ff7d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['word_en', 'word_fr'],\n",
            "    num_rows: 492\n",
            "}) \n",
            "\n",
            "{'word_en': ['abandon', 'abbe', 'abdomen', 'abdominal', 'aberration', 'abolition', 'abominable', 'absence', 'absolute', 'absolution'], 'word_fr': ['abandon', 'abbé', 'abdomen', 'abdominal', 'aberration', 'abolition', 'abominable', 'absence', 'absolu', 'absolution']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model ##"
      ],
      "metadata": {
        "id": "qyBJxKpF-9wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "# Load tokenizer and model\n",
        "model_name = \"xlm-roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Model for <mask> approach\n",
        "pretrained_model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "# Freeze and unfreeze x encoder layers\n",
        "for param in pretrained_model.base_model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in pretrained_model.base_model.encoder.layer[-5:].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(tokenizer)"
      ],
      "metadata": {
        "id": "vQlmoRnEQykz",
        "outputId": "a071f4aa-962d-46df-badc-7652c9707703",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XLMRobertaTokenizerFast(name_or_path='xlm-roberta-base', vocab_size=250002, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t250001: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
            "}\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess Dataset ##"
      ],
      "metadata": {
        "id": "51DQW-EYKURY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    \"\"\"\n",
        "    Tokenizes input words, replaces the French word with <mask>,\n",
        "    and assigns ALL subword tokens (BytePair Encoding) of the correct target\n",
        "    word as labels.\n",
        "\n",
        "    Args:\n",
        "        examples (dict): A batch of English-French cognate pairs in dictionary format:\n",
        "                         {\"word_en\": [...], \"word_fr\": [...]}\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing:\n",
        "            - input_ids: Tokenized sentences with <mask>\n",
        "            - attention_mask: Mask indicating valid tokens\n",
        "            - labels: Correct token IDs for the French word at the <mask> position\n",
        "    \"\"\"\n",
        "    # Construct masked input sentences\n",
        "    masked_sentences = [\n",
        "        f\"In English, the word is {word_en}. En Français, le mot est {tokenizer.mask_token}.\"\n",
        "        for word_en in examples[\"word_en\"]\n",
        "    ]\n",
        "\n",
        "    # Tokenize input sentences\n",
        "    model_inputs = tokenizer(masked_sentences, max_length=20, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Find <mask> token indices\n",
        "    mask_indices = [\n",
        "        [i for i, token_id in enumerate(input_ids) if token_id == tokenizer.mask_token_id]\n",
        "        for input_ids in model_inputs[\"input_ids\"]\n",
        "    ]\n",
        "\n",
        "    # Tokenize target words (French cognates) WITHOUT special tokens\n",
        "    target_tokens = tokenizer(examples[\"word_fr\"], add_special_tokens=False)[\"input_ids\"]\n",
        "\n",
        "    # Initialize label tensor with -100 (ignored positions)\n",
        "    model_inputs[\"labels\"] = [[-100] * len(input_ids) for input_ids in model_inputs[\"input_ids\"]]\n",
        "\n",
        "    # Assign correct token IDs at the <mask> position\n",
        "    for i, mask_pos in enumerate(mask_indices):\n",
        "        if mask_pos and target_tokens[i]:       # Ensure <mask> is found and target word is valid\n",
        "            for j, token_id in enumerate(target_tokens[i]):     # Assign all subword tokens\n",
        "                if mask_pos[0] + j < len(model_inputs[\"labels\"][i]):        # Avoid index errors\n",
        "                    model_inputs[\"labels\"][i][mask_pos[0] + j - 1] = token_id\n",
        "\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "zY7epkJEKTmg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Apply preprocessing to the dataset\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Verify structure\n",
        "print(tokenized_dataset)"
      ],
      "metadata": {
        "id": "hdB5m8srKlUB",
        "outputId": "5ce4ef13-1837-4df5-aa59-1257c7803885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "0ef7e4059c0d4db5a07306d1acbb1477",
            "f8bcefe5374646d4a7b48eef63d859e1",
            "d261f83156f3484280dc94f52cbe2b8f",
            "16b70746cd69408197c1a0733d050fb4",
            "6fb6de97f190461e922427925c1a898c",
            "37196bc6f4194ed0b1534d67cc4bb1ef",
            "51ff10199c93443db58318e6be1ca744",
            "94fc2ea1ad30407abc010715cab85409",
            "a250dbbe193a446e8751d663c79683f7",
            "f0d21712b5b446e8a2de84dbc4143cda",
            "2a30c3ff3811445a9384ba381815f953"
          ]
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/492 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ef7e4059c0d4db5a07306d1acbb1477"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['word_en', 'word_fr', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 492\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Shuffle the dataset\n",
        "tokenized_dataset = tokenized_dataset.shuffle(seed=20)\n",
        "\n",
        "# Compute split sizes\n",
        "total_size = len(tokenized_dataset)\n",
        "train_size = int(0.7 * total_size)      # 70% training\n",
        "val_size = int(0.2 * total_size)        # 20% validation\n",
        "test_size = total_size - (train_size + val_size)        # 10% test\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset = tokenized_dataset.select(range(train_size))\n",
        "val_dataset = tokenized_dataset.select(range(train_size, train_size + val_size))\n",
        "test_dataset = tokenized_dataset.select(range(train_size + val_size, total_size))\n",
        "\n",
        "# Verify splits\n",
        "print(f\"Total samples: {total_size}\")\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "jU3LedPpLF3D",
        "outputId": "9d265689-60f7-4905-cbbd-aa429eb6c45c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 492\n",
            "Training samples: 344\n",
            "Validation samples: 98\n",
            "Test samples: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a sample processed example\n",
        "example = tokenized_dataset[0]\n",
        "\n",
        "# Decode back to text to verify tokenization\n",
        "decoded_input = tokenizer.decode(example[\"input_ids\"])\n",
        "print(\"Tokenized Input:\", decoded_input)\n",
        "print(\"Labels (Token IDs):\", example[\"labels\"])\n",
        "\n",
        "# Decode the tokenized labels to check if they correctly represent the French word\n",
        "decoded_label_tokens = tokenizer.convert_ids_to_tokens([id for id in example[\"labels\"] if id != -100])\n",
        "print(\"Decoded Label Tokens:\", decoded_label_tokens)"
      ],
      "metadata": {
        "id": "o5PpfR4ZaIUR",
        "outputId": "868dc068-6665-4359-8bd4-e6e9af17cc9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Input: <s> In English, the word is parchment. En Français, le mot est<mask> </s>\n",
            "Labels (Token IDs): [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 366, 1430, 1249, -100]\n",
            "Decoded Label Tokens: ['▁par', 'che', 'min']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Pretrained Model ##"
      ],
      "metadata": {
        "id": "RSkJL2_U2WM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the evaluation function\n",
        "def evaluate_mask_accuracy(model, test_dataset, tokenizer, top_k=5):\n",
        "    \"\"\"\n",
        "    Evaluates the accuracy of a masked language model on a cognate dataset.\n",
        "\n",
        "    Args:\n",
        "        model: The pretrained or fine-tuned masked language model.\n",
        "        test_dataset: Hugging Face tokenized dataset with masked inputs.\n",
        "        tokenizer: The tokenizer corresponding to the model.\n",
        "        top_k (int): Number of top predictions to consider for accuracy.\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy of the model on the dataset.\n",
        "    \"\"\"\n",
        "    correct_predictions = 0\n",
        "    total_samples = len(test_dataset)\n",
        "\n",
        "    for i in range(total_samples):\n",
        "        # Get tokenized input and expected labels\n",
        "        example = test_dataset[i]\n",
        "        input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0)  # Add batch dimension\n",
        "        labels = example[\"labels\"]  # Token IDs for masked French word(s)\n",
        "        attention_mask = torch.tensor(example[\"attention_mask\"]).unsqueeze(0)  # Ensure padding is properly masked\n",
        "\n",
        "        # Find the <mask> token index\n",
        "        mask_token_index = (input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)\n",
        "\n",
        "        if len(mask_token_index[0]) == 0:  # If no <mask> token is found\n",
        "            print(f\"Error: No {tokenizer.mask_token} token found in instance {i+1}\")\n",
        "            continue\n",
        "\n",
        "        mask_token_index = mask_token_index[1]  # Get index positions of <mask> token\n",
        "\n",
        "        # Forward pass through the model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids)\n",
        "        logits = outputs.logits  # Prediction scores for each token in vocabulary\n",
        "\n",
        "        # Get top-k predictions for each masked token\n",
        "        mask_token_logits = logits[0, mask_token_index, :]\n",
        "        top_k_tokens = torch.topk(mask_token_logits, k=top_k, dim=-1).indices.tolist()\n",
        "\n",
        "        # Decode predictions into words\n",
        "        predicted_words = [[tokenizer.decode([token]).strip() for token in top_k] for top_k in top_k_tokens]\n",
        "\n",
        "        # Decode and format the expected French word\n",
        "        expected_tokens = [id for id in labels if id != -100]  # Remove ignored tokens\n",
        "        expected_word_pieces = tokenizer.convert_ids_to_tokens(expected_tokens)\n",
        "        expected_word = \"\".join([piece.lstrip(\"▁\") for piece in expected_word_pieces])  # Concatenate and remove '▁'\n",
        "\n",
        "\n",
        "        # Log predictions\n",
        "        print(f\"Instance {i+1}:\")\n",
        "        print(f\"    Tokenized Input: {tokenizer.decode(example['input_ids'])}\")\n",
        "        print(f\"    Expected French word: {expected_word}\")\n",
        "        print(f\"    Predicted MASK words (Top-{top_k}): {predicted_words}\\n\")\n",
        "\n",
        "        # Check if all expected subword tokens are predicted in top-k\n",
        "        if any(expected_word in pred_list for pred_list in predicted_words):\n",
        "            correct_predictions += 1\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = correct_predictions / total_samples if total_samples > 0 else 0.0\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# Evaluate the accuracy of pretrained model\n",
        "accuracy = evaluate_mask_accuracy(pretrained_model, test_dataset, tokenizer, top_k=5)\n",
        "print(f\"Accuracy of the model: {accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imi10wc3x9E-",
        "outputId": "6ac99229-ac50-4227-c354-226229b676fe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instance 1:\n",
            "    Tokenized Input: <s> In English, the word is abdominal. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: abdominal\n",
            "    Predicted MASK words (Top-5): [['abdominal', 'muscle', 'bouche', ':', 'stomach']]\n",
            "\n",
            "Instance 2:\n",
            "    Tokenized Input: <s> In English, the word is alarm. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: alarme\n",
            "    Predicted MASK words (Top-5): [['alarm', 'réveil', 'Alarm', ':', 'alert']]\n",
            "\n",
            "Instance 3:\n",
            "    Tokenized Input: <s> In English, the word is syndicate. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: syndicat\n",
            "    Predicted MASK words (Top-5): [['syndicat', 'collective', ':', 'production', 'de']]\n",
            "\n",
            "Instance 4:\n",
            "    Tokenized Input: <s> In English, the word is affirmative. En Français, le mot est<mask> </s>\n",
            "    Expected French word: affirmatif\n",
            "    Predicted MASK words (Top-5): [[':', ':', 'de', 'expression', 'souvent']]\n",
            "\n",
            "Instance 5:\n",
            "    Tokenized Input: <s> In English, the word is rehabilitation. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: réhabilitation\n",
            "    Predicted MASK words (Top-5): [['recovery', ':', ':', 'de', 'reparation']]\n",
            "\n",
            "Instance 6:\n",
            "    Tokenized Input: <s> In English, the word is activity. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: activité\n",
            "    Predicted MASK words (Top-5): [['activity', 'activité', 'travail', 'action', 'participation']]\n",
            "\n",
            "Instance 7:\n",
            "    Tokenized Input: <s> In English, the word is imperfect. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: imparfait\n",
            "    Predicted MASK words (Top-5): [['parfait', 'vrai', 'perfect', 'correct', 'latin']]\n",
            "\n",
            "Instance 8:\n",
            "    Tokenized Input: <s> In English, the word is fiber. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: fibre\n",
            "    Predicted MASK words (Top-5): [['fiber', 'fibre', 'grain', 'air', 'fils']]\n",
            "\n",
            "Instance 9:\n",
            "    Tokenized Input: <s> In English, the word is festival. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: festival\n",
            "    Predicted MASK words (Top-5): [['festival', 'fête', 'Festival', 'concert', 'spectacle']]\n",
            "\n",
            "Instance 10:\n",
            "    Tokenized Input: <s> In English, the word is absurd. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: absurde\n",
            "    Predicted MASK words (Top-5): [['absurd', 'bizarre', 'impossible', 'étrange', 'drôle']]\n",
            "\n",
            "Instance 11:\n",
            "    Tokenized Input: <s> In English, the word is banquet. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: banquet\n",
            "    Predicted MASK words (Top-5): [['banque', 'restaurant', ':', 'table', 'manger']]\n",
            "\n",
            "Instance 12:\n",
            "    Tokenized Input: <s> In English, the word is operational. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: opérationel\n",
            "    Predicted MASK words (Top-5): [['operation', 'active', 'functional', 'operator', 'utilisé']]\n",
            "\n",
            "Instance 13:\n",
            "    Tokenized Input: <s> In English, the word is ballet. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: ballet\n",
            "    Predicted MASK words (Top-5): [['théâtre', 'ball', ':', ':', 'balet']]\n",
            "\n",
            "Instance 14:\n",
            "    Tokenized Input: <s> In English, the word is author. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: auteur\n",
            "    Predicted MASK words (Top-5): [['author', 'autor', 'Author', 'écrit', 'publication']]\n",
            "\n",
            "Instance 15:\n",
            "    Tokenized Input: <s> In English, the word is reparation. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: réparation\n",
            "    Predicted MASK words (Top-5): [['reparation', 'réparation', 'repair', 'restauration', 'service']]\n",
            "\n",
            "Instance 16:\n",
            "    Tokenized Input: <s> In English, the word is negative. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: négatif\n",
            "    Predicted MASK words (Top-5): [['positive', 'positif', 'négatif', 'negative', 'negativ']]\n",
            "\n",
            "Instance 17:\n",
            "    Tokenized Input: <s> In English, the word is football. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: football\n",
            "    Predicted MASK words (Top-5): [['football', 'Football', 'rugby', 'baseball', 'sport']]\n",
            "\n",
            "Instance 18:\n",
            "    Tokenized Input: <s> In English, the word is group. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: groupe\n",
            "    Predicted MASK words (Top-5): [['groupe', 'group', 'collective', 'Group', 'famille']]\n",
            "\n",
            "Instance 19:\n",
            "    Tokenized Input: <s> In English, the word is absence. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: absence\n",
            "    Predicted MASK words (Top-5): [['absent', 'absence', ':', ':', 'présence']]\n",
            "\n",
            "Instance 20:\n",
            "    Tokenized Input: <s> In English, the word is ligament. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: ligament\n",
            "    Predicted MASK words (Top-5): [['liga', 'division', ':', 'le', 'joint']]\n",
            "\n",
            "Instance 21:\n",
            "    Tokenized Input: <s> In English, the word is approximation. En Français, le mot est<mask> </s>\n",
            "    Expected French word: approximation\n",
            "    Predicted MASK words (Top-5): [['appro', 'environ', ':', 'impression', '']]\n",
            "\n",
            "Instance 22:\n",
            "    Tokenized Input: <s> In English, the word is composition. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: composition\n",
            "    Predicted MASK words (Top-5): [['composition', 'compose', 'structure', 'construction', 'composé']]\n",
            "\n",
            "Instance 23:\n",
            "    Tokenized Input: <s> In English, the word is rayon. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: rayon\n",
            "    Predicted MASK words (Top-5): [['rayon', 'rue', 'région', 'maison', 'château']]\n",
            "\n",
            "Instance 24:\n",
            "    Tokenized Input: <s> In English, the word is offensive. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: offensif\n",
            "    Predicted MASK words (Top-5): [['offensiv', ':', ':', 'incorrect', 'dominant']]\n",
            "\n",
            "Instance 25:\n",
            "    Tokenized Input: <s> In English, the word is reptile. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: reptile\n",
            "    Predicted MASK words (Top-5): [['animal', 'serpent', ':', 'animale', 'humain']]\n",
            "\n",
            "Instance 26:\n",
            "    Tokenized Input: <s> In English, the word is reason. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: raison\n",
            "    Predicted MASK words (Top-5): [['reason', 'raison', 'cause', 'excuse', 'rational']]\n",
            "\n",
            "Instance 27:\n",
            "    Tokenized Input: <s> In English, the word is demonstration. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: démonstration\n",
            "    Predicted MASK words (Top-5): [['demonstra', 'demonstrat', 'manifestation', 'show', 'illustration']]\n",
            "\n",
            "Instance 28:\n",
            "    Tokenized Input: <s> In English, the word is orphan. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: orphelin\n",
            "    Predicted MASK words (Top-5): [[':', 'enfant', ':', 'homme', 'autre']]\n",
            "\n",
            "Instance 29:\n",
            "    Tokenized Input: <s> In English, the word is accord. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: accord\n",
            "    Predicted MASK words (Top-5): [['accord', 'union', 'dialogue', 'commun', 'accent']]\n",
            "\n",
            "Instance 30:\n",
            "    Tokenized Input: <s> In English, the word is civilization. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: civilisation\n",
            "    Predicted MASK words (Top-5): [['nation', ':', ':', 'population', 'société']]\n",
            "\n",
            "Instance 31:\n",
            "    Tokenized Input: <s> In English, the word is gallant. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: galant\n",
            "    Predicted MASK words (Top-5): [['anglais', 'latin', 'français', ':', 'grec']]\n",
            "\n",
            "Instance 32:\n",
            "    Tokenized Input: <s> In English, the word is independent. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: indépendant\n",
            "    Predicted MASK words (Top-5): [['independent', 'indépendant', 'dependent', 'anglais', 'distinct']]\n",
            "\n",
            "Instance 33:\n",
            "    Tokenized Input: <s> In English, the word is ceremonial. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: cérémonial\n",
            "    Predicted MASK words (Top-5): [['cérémonie', 'formal', ':', 'ceremoni', ':']]\n",
            "\n",
            "Instance 34:\n",
            "    Tokenized Input: <s> In English, the word is detail. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: détail\n",
            "    Predicted MASK words (Top-5): [['detail', 'détail', 'détails', 'description', 'Detail']]\n",
            "\n",
            "Instance 35:\n",
            "    Tokenized Input: <s> In English, the word is rampart. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: rempart\n",
            "    Predicted MASK words (Top-5): [['ram', ':', ':', 'rim', 'marqué']]\n",
            "\n",
            "Instance 36:\n",
            "    Tokenized Input: <s> In English, the word is zircon. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: zircon\n",
            "    Predicted MASK words (Top-5): [['zir', 'signe', ':', ':', 'serpent']]\n",
            "\n",
            "Instance 37:\n",
            "    Tokenized Input: <s> In English, the word is impostor. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: imposteur\n",
            "    Predicted MASK words (Top-5): [[':', ':', 'de', 'un', '...']]\n",
            "\n",
            "Instance 38:\n",
            "    Tokenized Input: <s> In English, the word is liquid. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: liquide\n",
            "    Predicted MASK words (Top-5): [['liquid', 'solide', 'fluid', 'acid', 'solid']]\n",
            "\n",
            "Instance 39:\n",
            "    Tokenized Input: <s> In English, the word is legal. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: légal\n",
            "    Predicted MASK words (Top-5): [['interdit', 'français', 'légal', 'libre', 'legal']]\n",
            "\n",
            "Instance 40:\n",
            "    Tokenized Input: <s> In English, the word is admirable. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: admirable\n",
            "    Predicted MASK words (Top-5): [['excellent', ':', ':', 'Excellent', 'admira']]\n",
            "\n",
            "Instance 41:\n",
            "    Tokenized Input: <s> In English, the word is human. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: humain\n",
            "    Predicted MASK words (Top-5): [['humain', 'homme', 'human', 'humaine', 'femme']]\n",
            "\n",
            "Instance 42:\n",
            "    Tokenized Input: <s> In English, the word is destruction. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: destruction\n",
            "    Predicted MASK words (Top-5): [['destruction', 'mort', 'morte', 'dommage', 'destroy']]\n",
            "\n",
            "Instance 43:\n",
            "    Tokenized Input: <s> In English, the word is catastrophe. En Français, le mot est<mask> </s>\n",
            "    Expected French word: catastrophe\n",
            "    Predicted MASK words (Top-5): [[':', ':', 'de', '.', 'cata']]\n",
            "\n",
            "Instance 44:\n",
            "    Tokenized Input: <s> In English, the word is implicit. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: implicite\n",
            "    Predicted MASK words (Top-5): [['implicit', 'explicit', 'écrit', 'plural', 'initial']]\n",
            "\n",
            "Instance 45:\n",
            "    Tokenized Input: <s> In English, the word is commerce. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: commerce\n",
            "    Predicted MASK words (Top-5): [['commerce', 'vendre', 'production', 'entreprise', 'travail']]\n",
            "\n",
            "Instance 46:\n",
            "    Tokenized Input: <s> In English, the word is prejudice. En Français, le mot est<mask> </s>\n",
            "    Expected French word: préjudice\n",
            "    Predicted MASK words (Top-5): [[':', ':', 'pour', 'de', '.']]\n",
            "\n",
            "Instance 47:\n",
            "    Tokenized Input: <s> In English, the word is button. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: bouton\n",
            "    Predicted MASK words (Top-5): [['bouton', 'button', 'fenêtre', 'page', 'contact']]\n",
            "\n",
            "Instance 48:\n",
            "    Tokenized Input: <s> In English, the word is color. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: couleur\n",
            "    Predicted MASK words (Top-5): [['couleur', 'blanc', 'bleu', 'noir', 'color']]\n",
            "\n",
            "Instance 49:\n",
            "    Tokenized Input: <s> In English, the word is exception. En Français, le mot est<mask> .</s><pad>\n",
            "    Expected French word: exception\n",
            "    Predicted MASK words (Top-5): [['exception', 'règle', 'restriction', 'condition', 'perfection']]\n",
            "\n",
            "Instance 50:\n",
            "    Tokenized Input: <s> In English, the word is obscurity. En Français, le mot est<mask> .</s>\n",
            "    Expected French word: obscurité\n",
            "    Predicted MASK words (Top-5): [['obscur', ':', ':', 'confusion', 'un']]\n",
            "\n",
            "Accuracy of the model: 46.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetune Model ##"
      ],
      "metadata": {
        "id": "8BGx9YByADkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "# Load accuracy metric\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "# Define metric computation function\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Computes accuracy during validation by ignoring padding tokens.\n",
        "    \"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Flatten predictions and labels (remove -100 labels)\n",
        "    flattened_predictions = []\n",
        "    flattened_labels = []\n",
        "\n",
        "    for pred, label in zip(predictions, labels):\n",
        "        for p, l in zip(pred, label):\n",
        "            if l != -100:       # Ignore padding token labels\n",
        "                flattened_predictions.append(p)\n",
        "                flattened_labels.append(l)\n",
        "\n",
        "    return accuracy.compute(predictions=flattened_predictions, references=flattened_labels)"
      ],
      "metadata": {
        "id": "_m7n4ywIAAr8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Define training arguments\n",
        "arguments = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Colab Notebooks/cognate_trainer\",\n",
        "     per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    logging_steps=1,\n",
        "    num_train_epochs=6,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    learning_rate=3e-5,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    warmup_ratio=0.1,\n",
        "    gradient_accumulation_steps=2,\n",
        "    weight_decay=0.01,\n",
        "    max_grad_norm=1.0,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to='none',\n",
        "    seed=224,\n",
        "    fp16=True,\n",
        "    dataloader_drop_last=True,\n",
        "    ignore_data_skip=True\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=pretrained_model,\n",
        "    args=arguments,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    processing_class=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "bWWSL8L2Arwp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "mppzuBT_BLcA",
        "outputId": "16700ef8-5f48-45a5-b102-8c12b0bf2e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [24/40 03:50 < 02:47, 0.10 it/s, Epoch 4.60/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>18.461500</td>\n",
              "      <td>6.450321</td>\n",
              "      <td>0.093567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>9.057300</td>\n",
              "      <td>3.779105</td>\n",
              "      <td>0.421053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>7.026700</td>\n",
              "      <td>3.397326</td>\n",
              "      <td>0.467836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>7.202400</td>\n",
              "      <td>2.936474</td>\n",
              "      <td>0.526316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 07:01, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>18.461500</td>\n",
              "      <td>6.450321</td>\n",
              "      <td>0.093567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>9.057300</td>\n",
              "      <td>3.779105</td>\n",
              "      <td>0.421053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>7.026700</td>\n",
              "      <td>3.397326</td>\n",
              "      <td>0.467836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>7.202400</td>\n",
              "      <td>2.936474</td>\n",
              "      <td>0.526316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>5.629400</td>\n",
              "      <td>2.841316</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4.503100</td>\n",
              "      <td>2.689695</td>\n",
              "      <td>0.567251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4.648600</td>\n",
              "      <td>2.625007</td>\n",
              "      <td>0.561404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>4.878000</td>\n",
              "      <td>2.612090</td>\n",
              "      <td>0.561404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=40, training_loss=9.672758382558822, metrics={'train_runtime': 428.9758, 'train_samples_per_second': 6.415, 'train_steps_per_second': 0.093, 'total_flos': 26387905536000.0, 'train_loss': 9.672758382558822, 'epoch': 8.0})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the finetuned model\n",
        "output_dir = \"/content/drive/MyDrive/Colab Notebooks/cognate_trainer_best_model\"\n",
        "trainer.save_model(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "print(\"\\nTest Results:\")\n",
        "print(test_results)"
      ],
      "metadata": {
        "id": "foKaxwLvBRK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load finetuned model and tokenizer\n",
        "finetuned_model = AutoModelForMaskedLM.from_pretrained(output_dir)\n",
        "fine_tokenizer = AutoTokenizer.from_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "uH0FauszSrrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Finetuned Model ##"
      ],
      "metadata": {
        "id": "b7OyuoZQUpTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the accuracy of finetuned model\n",
        "accuracy = evaluate_mask_accuracy(finetuned_model, test_dataset, fine_tokenizer, top_k=5)\n",
        "print(f\"Accuracy of the model: {accuracy:.2%}\")"
      ],
      "metadata": {
        "id": "MkpzXzLxTrbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization ##"
      ],
      "metadata": {
        "id": "j1G1KwYyU02w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "pretrained_model.config.output_hidden_states = True\n",
        "finetuned_model.config.output_hidden_states = True\n",
        "\n",
        "def visualize_embeddings_2D(model, tokenizer, dataset, method=\"pca\", sample_size=50):\n",
        "    \"\"\"\n",
        "    Visualizes word embeddings from the model in 2D space using PCA or t-SNE.\n",
        "\n",
        "    Args:\n",
        "        model: The masked language model (pretrained or fine-tuned).\n",
        "        tokenizer: Tokenizer corresponding to the model.\n",
        "        dataset: Hugging Face Dataset with preprocessed inputs.\n",
        "        method (str): Dimensionality reduction method (\"pca\" or \"tsne\").\n",
        "        sample_size (int): Number of word pairs to sample for visualization.\n",
        "    \"\"\"\n",
        "    words = []\n",
        "    embeddings = []\n",
        "\n",
        "    # Sample a subset for visualization\n",
        "    dataset = dataset.select(range(min(sample_size, len(dataset))))\n",
        "\n",
        "    for example in dataset:\n",
        "        input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0)  # Add batch dimension\n",
        "        attention_mask = torch.tensor(example[\"attention_mask\"]).unsqueeze(0)\n",
        "\n",
        "        # Find the <mask> token index\n",
        "        mask_token_index = (input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)\n",
        "\n",
        "        if len(mask_token_index[0]) == 0:\n",
        "            continue  # Skip instances where no <mask> token is found\n",
        "\n",
        "        mask_token_index = mask_token_index[1]  # Extract index positions\n",
        "\n",
        "        # Extract model embeddings\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "            hidden_states = outputs.hidden_states[-1]  # Get the last hidden layer\n",
        "\n",
        "        # Extract embeddings for <mask> token (mean over all masked positions)\n",
        "        mask_embeddings = hidden_states[0, mask_token_index, :].mean(dim=0).numpy()\n",
        "\n",
        "        embeddings.append(mask_embeddings)\n",
        "\n",
        "        # Store words (English and French)\n",
        "        words.append(f\"{example['word_en']} → {example['word_fr']}\")\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    embeddings = np.array(embeddings)\n",
        "\n",
        "    # Reduce dimensions\n",
        "    if method == \"pca\":\n",
        "        reducer = PCA(n_components=2)\n",
        "    elif method == \"tsne\":\n",
        "        reducer = TSNE(n_components=2, perplexity=10, random_state=42)\n",
        "    else:\n",
        "        raise ValueError(\"Method must be 'pca' or 'tsne'.\")\n",
        "\n",
        "    reduced_embeddings = reducer.fit_transform(embeddings)\n",
        "\n",
        "    # Plot embeddings\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], alpha=0.7, cmap=\"coolwarm\")\n",
        "\n",
        "    # Annotate points with word pairs\n",
        "    for i, word_pair in enumerate(words):\n",
        "        plt.text(reduced_embeddings[i, 0], reduced_embeddings[i, 1], word_pair, fontsize=9, ha='right', va='bottom')\n",
        "\n",
        "    plt.title(f\"2D Projection of Word Embeddings ({method.upper()})\")\n",
        "    plt.xlabel(\"Component 1\")\n",
        "    plt.ylabel(\"Component 2\")\n",
        "    plt.show()\n",
        "\n",
        "# Call function for both models using PCA\n",
        "visualize_embeddings_2D(pretrained_model, tokenizer, test_dataset, method=\"pca\")\n",
        "visualize_embeddings_2D(finetuned_model, tokenizer, test_dataset, method=\"pca\")"
      ],
      "metadata": {
        "id": "VKF4-FGwU0Qz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}