{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d0745fb658e24000bb40e6f198e21d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02d5b53bf8844606be0676f42550b3e7",
              "IPY_MODEL_89affbb2474642bfb4470524775d00e6",
              "IPY_MODEL_835ba9c47c18404985ca51eaf20f8887"
            ],
            "layout": "IPY_MODEL_1cec46f74f494f8fa26a3f314411b299"
          }
        },
        "02d5b53bf8844606be0676f42550b3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37301277f0e5421aac9b251424a017cf",
            "placeholder": "​",
            "style": "IPY_MODEL_cb08466f33e54549a89722ef0fd6cba6",
            "value": "Map: 100%"
          }
        },
        "89affbb2474642bfb4470524775d00e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ba0c7ce1db241438557ba8c9dfcc652",
            "max": 8000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22fa20be89f146099d5c7dafe36b0de7",
            "value": 8000
          }
        },
        "835ba9c47c18404985ca51eaf20f8887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9c73024e1f84985a7b31599dc642855",
            "placeholder": "​",
            "style": "IPY_MODEL_0c4677627acb408d9b0d398de63ca7bd",
            "value": " 8000/8000 [00:02&lt;00:00, 2652.75 examples/s]"
          }
        },
        "1cec46f74f494f8fa26a3f314411b299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37301277f0e5421aac9b251424a017cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb08466f33e54549a89722ef0fd6cba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ba0c7ce1db241438557ba8c9dfcc652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22fa20be89f146099d5c7dafe36b0de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9c73024e1f84985a7b31599dc642855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c4677627acb408d9b0d398de63ca7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08635ea8e21845509261871b3a728f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40963c31c3574faab26b0ff2e872a83e",
              "IPY_MODEL_8abc8fcdc60a47e6af3475fdb5e1dffe",
              "IPY_MODEL_07757a53ee6b403b8de4604905175ba4"
            ],
            "layout": "IPY_MODEL_b573c7b7157f44c18163cb1d837a575a"
          }
        },
        "40963c31c3574faab26b0ff2e872a83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82ccff5fb05248eca8ba76c8509f5314",
            "placeholder": "​",
            "style": "IPY_MODEL_977e99dd95a64ba0961884051e230af1",
            "value": "Map: 100%"
          }
        },
        "8abc8fcdc60a47e6af3475fdb5e1dffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b880fe85695d418f84f336ad564b2f77",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae1cc91a35314207807633bfce130886",
            "value": 1000
          }
        },
        "07757a53ee6b403b8de4604905175ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17b8cbbc6be14fc8bf3c8ce99b8371e8",
            "placeholder": "​",
            "style": "IPY_MODEL_f784d9ce78954b849d8a6e7e8ce07a8d",
            "value": " 1000/1000 [00:00&lt;00:00, 2310.40 examples/s]"
          }
        },
        "b573c7b7157f44c18163cb1d837a575a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82ccff5fb05248eca8ba76c8509f5314": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "977e99dd95a64ba0961884051e230af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b880fe85695d418f84f336ad564b2f77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae1cc91a35314207807633bfce130886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17b8cbbc6be14fc8bf3c8ce99b8371e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f784d9ce78954b849d8a6e7e8ce07a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3212b1bdc5744f4a858d0f3a20df071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_758b35cc9bef4f208eddfc89892b46e6",
              "IPY_MODEL_6b01005ad25144dbadd26d125a2a4e9e",
              "IPY_MODEL_02adbe08a35345af8d4b5bcc4facbf7f"
            ],
            "layout": "IPY_MODEL_daafc10fc97b41d5af0fbc02bba9587f"
          }
        },
        "758b35cc9bef4f208eddfc89892b46e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d239d74f55c84a839086584c5d6b3628",
            "placeholder": "​",
            "style": "IPY_MODEL_ef80d28420054e2384b2dd50260039f7",
            "value": "Map: 100%"
          }
        },
        "6b01005ad25144dbadd26d125a2a4e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de3eb409bf424fbba7a373dde3c040da",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c41b7e7736f348d99a704ab7992bbbfb",
            "value": 1000
          }
        },
        "02adbe08a35345af8d4b5bcc4facbf7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e913960cea14cb8b87c2f21604bdbfc",
            "placeholder": "​",
            "style": "IPY_MODEL_051954ffb5564331b0754359ea4854d1",
            "value": " 1000/1000 [00:00&lt;00:00, 2159.64 examples/s]"
          }
        },
        "daafc10fc97b41d5af0fbc02bba9587f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d239d74f55c84a839086584c5d6b3628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef80d28420054e2384b2dd50260039f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de3eb409bf424fbba7a373dde3c040da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c41b7e7736f348d99a704ab7992bbbfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e913960cea14cb8b87c2f21604bdbfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "051954ffb5564331b0754359ea4854d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fubotz/ICL_2024W/blob/main/FinalProject_Fabian_SCHAMBECK_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Project: Finetuning a Pretrained Multilingual Model for Cognate Detection\n",
        "\n",
        "Methods: Nearest Neighbor / [MASK]\n",
        "\n",
        "Model: distilbert-base-multilingual-cased\n",
        "\n",
        "Dataset: Helsinki-NLP / europarl (en-fr split)"
      ],
      "metadata": {
        "id": "N4_fSCGEAFZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bertviz\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install optuna\n",
        "!pip install scikit-learn\n",
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "metadata": {
        "id": "v1II96WS0W56",
        "outputId": "a1d6ce9d-a67a-4d45-869a-4c5129248ac2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bertviz in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.11/dist-packages (from bertviz) (4.47.1)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.11/dist-packages (from bertviz) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from bertviz) (4.67.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from bertviz) (1.36.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bertviz) (2.32.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from bertviz) (2024.11.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from bertviz) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0->bertviz) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0->bertviz) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.37.0,>=1.36.6 in /usr/local/lib/python3.11/dist-packages (from boto3->bertviz) (1.36.6)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->bertviz) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3->bertviz) (0.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.37.0,>=1.36.6->boto3->bertviz) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0->bertviz) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.37.0,>=1.36.6->boto3->bertviz) (1.17.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.37)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.0-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.4/383.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.8 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.0\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwUn733bt7lE",
        "outputId": "06060448-efc6-4f4c-a0cf-fe965a3214e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM\n",
        "\n",
        "# Load tokenizer and models\n",
        "model_name = \"distilbert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Model for Nearest Neighbor Approach\n",
        "embedding_model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Model for [MASK] Approach\n",
        "mlm_model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "print(tokenizer)"
      ],
      "metadata": {
        "id": "vQlmoRnEQykz",
        "outputId": "e23b3f81-110f-4fb5-cafc-d668d035cb06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBertTokenizerFast(name_or_path='distilbert-base-multilingual-cased', vocab_size=119547, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Get the embeddings for the model's vocabulary\n",
        "def get_vocab_embeddings(tokenizer, model):\n",
        "    \"\"\"\n",
        "    Extract embeddings for all meaningful tokens in the model's vocabulary.\n",
        "    Filters out subwords, special tokens, and non-alphabetical tokens.\n",
        "    \"\"\"\n",
        "    vocab_size = len(tokenizer)\n",
        "    embeddings = []\n",
        "    words = []\n",
        "\n",
        "    for token_id in range(vocab_size):\n",
        "        token = tokenizer.convert_ids_to_tokens(token_id)\n",
        "        # Filter: Exclude subwords (tokens starting with ##), special tokens, and non-alphabetical tokens\n",
        "        if token.isalpha() and not token.startswith(\"##\"):\n",
        "            words.append(token)\n",
        "            with torch.no_grad():\n",
        "                # Create a tensor for the token and get its embedding\n",
        "                inputs = torch.tensor([[token_id]])\n",
        "                outputs = model.embeddings.word_embeddings(inputs)\n",
        "                embeddings.append(outputs[0].squeeze(0).numpy())\n",
        "\n",
        "    return words, np.array(embeddings)"
      ],
      "metadata": {
        "id": "tHjX0cUbyz4A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve embedding for a single word\n",
        "def get_embedding(word, tokenizer, model):\n",
        "    \"\"\"\n",
        "    Retrieve the embedding for a single word.\n",
        "    \"\"\"\n",
        "    tokens = tokenizer(word, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "        embedding = outputs.last_hidden_state[:, 0, :]  # [CLS] token embedding\n",
        "    return embedding.squeeze(0)"
      ],
      "metadata": {
        "id": "WjhAnUUKy8mM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Pretrained Model ##"
      ],
      "metadata": {
        "id": "RSkJL2_U2WM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# NN aproach\n",
        "def find_nearest_neighbors_direct(word_en, tokenizer, model, vocab_embeddings, vocab_words, top_k=5):\n",
        "    \"\"\"\n",
        "    Find the nearest neighbors for an input word directly from the model's filtered vocabulary.\n",
        "    \"\"\"\n",
        "    # Get the embedding for the input word\n",
        "    en_embedding = get_embedding(word_en, tokenizer, model).numpy()\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    similarities = cosine_similarity([en_embedding], vocab_embeddings)[0]\n",
        "\n",
        "    # Get the top_k most similar tokens\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    top_tokens = [(vocab_words[idx], similarities[idx]) for idx in top_indices]\n",
        "\n",
        "    return top_tokens"
      ],
      "metadata": {
        "id": "ymSZoNR7zCYd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [MASK] approach\n",
        "def predict_with_mask(word_en, tokenizer, model, top_k=5):\n",
        "    \"\"\"\n",
        "    Predict the most probable French words for the given English word using the [MASK] approach.\n",
        "    \"\"\"\n",
        "    # Define the prompt with the [MASK] token\n",
        "    sentence = f\"The English word is '{word_en}'. Le mot français est [MASK].\"\n",
        "\n",
        "    # Tokenize the sentence\n",
        "    tokens = tokenizer(sentence, return_tensors=\"pt\")\n",
        "\n",
        "    # Identify the [MASK] token index\n",
        "    mask_token_index = torch.where(tokens[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Get the top_k predictions for the [MASK] token\n",
        "    mask_token_logits = logits[0, mask_token_index, :]\n",
        "    top_token_ids = torch.topk(mask_token_logits, top_k, dim=-1).indices[0].tolist()\n",
        "\n",
        "    # Decode the predicted tokens into words\n",
        "    predictions = [tokenizer.decode([token_id]).strip() for token_id in top_token_ids]\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "cD0rNDkczIg-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hardcoded word pairs for evaluation (n=21) (taken from Frossard et al.)\n",
        "word_pairs = [\n",
        "    (\"academic\", \"académique\"),\n",
        "    (\"administrator\", \"administrateur\"),\n",
        "    (\"algorithm\", \"algorithme\"),\n",
        "    (\"chemical\", \"chimique\"),\n",
        "    (\"delicious\", \"délicieux\"),\n",
        "    (\"emotion\", \"émotion\"),\n",
        "    (\"exercise\", \"exercice\"),\n",
        "    (\"gender\", \"genre\"),\n",
        "    (\"gorilla\", \"gorille\"),\n",
        "    (\"loyalty\", \"loyauté\"),\n",
        "    (\"notation\", \"notamment\"),\n",
        "    (\"objective\", \"objectif\"),\n",
        "    (\"oratory\", \"oratoire\"),\n",
        "    (\"particle\", \"particule\"),\n",
        "    (\"quarter\", \"quartier\"),\n",
        "    (\"september\", \"septembre\"),\n",
        "    (\"skeleton\", \"squelette\"),\n",
        "    (\"traditionally\", \"traditionnellement\"),\n",
        "    (\"voice\", \"voix\"),\n",
        "    (\"west\", \"ouest\"),\n",
        "    (\"wine\", \"vin\"),\n",
        "]\n",
        "\n",
        "# Extract filtered vocabulary embeddings\n",
        "vocab_words, vocab_embeddings = get_vocab_embeddings(tokenizer, embedding_model)\n",
        "\n",
        "# Evaluate all words in the hardcoded list\n",
        "for word_en, word_fr in word_pairs:\n",
        "    print(f\"\\nProcessing '{word_en}' (expected: '{word_fr}')\")\n",
        "\n",
        "    # Nearest Neighbor Approach\n",
        "    nearest_neighbors = find_nearest_neighbors_direct(word_en, tokenizer, embedding_model, vocab_embeddings, vocab_words)\n",
        "\n",
        "    # [MASK] Approach\n",
        "    mask_predictions = predict_with_mask(word_en, tokenizer, mlm_model)\n",
        "\n",
        "    # Print results for Nearest Neighbors\n",
        "    print(f\"Nearest neighbors:\")\n",
        "    for token, similarity in nearest_neighbors:\n",
        "        print(f\"  {token}: {similarity:.4f}\")\n",
        "\n",
        "    # Print results for [MASK] Approach\n",
        "    print(f\"[MASK] predictions:\")\n",
        "    for prediction in mask_predictions:\n",
        "        print(f\"  {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq6LZQSnzP0Z",
        "outputId": "e5b5b038-e958-4aa3-d80c-2bc69a931256"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing 'academic' (expected: 'académique')\n",
            "Nearest neighbors:\n",
            "  only: 0.1267\n",
            "  Mad: 0.1172\n",
            "  Ancient: 0.1168\n",
            "  達: 0.1097\n",
            "  Flying: 0.1079\n",
            "[MASK] predictions:\n",
            "  inconnu\n",
            "  latin\n",
            "  scientifique\n",
            "  anglais\n",
            "  français\n",
            "\n",
            "Processing 'administrator' (expected: 'administrateur')\n",
            "Nearest neighbors:\n",
            "  only: 0.1250\n",
            "  شروع: 0.1145\n",
            "  нем: 0.1139\n",
            "  Bart: 0.1119\n",
            "  կամ: 0.1057\n",
            "[MASK] predictions:\n",
            "  inconnu\n",
            "  蹦\n",
            "  present\n",
            "  ancien\n",
            "  simple\n",
            "\n",
            "Processing 'algorithm' (expected: 'algorithme')\n",
            "Nearest neighbors:\n",
            "  schnell: 0.1322\n",
            "  Ergebnis: 0.1231\n",
            "  Flying: 0.1169\n",
            "  شروع: 0.1145\n",
            "  wahrscheinlich: 0.1110\n",
            "[MASK] predictions:\n",
            "  inconnu\n",
            "  蹦\n",
            "  proche\n",
            "  present\n",
            "  beteiligt\n",
            "\n",
            "Processing 'chemical' (expected: 'chimique')\n",
            "Nearest neighbors:\n",
            "  Pflanzen: 0.1225\n",
            "  ʸ: 0.1223\n",
            "  浦: 0.1155\n",
            "  only: 0.1125\n",
            "  πριν: 0.1115\n",
            "[MASK] predictions:\n",
            "  inconnu\n",
            "  simple\n",
            "  latin\n",
            "  proche\n",
            "  courant\n",
            "\n",
            "Processing 'delicious' (expected: 'délicieux')\n",
            "Nearest neighbors:\n",
            "  Ancient: 0.1184\n",
            "  only: 0.1132\n",
            "  flying: 0.1126\n",
            "  達: 0.1115\n",
            "  pur: 0.1069\n",
            "[MASK] predictions:\n",
            "  蹦\n",
            "  inconnu\n",
            "  simple\n",
            "  present\n",
            "  vrai\n",
            "\n",
            "Processing 'emotion' (expected: 'émotion')\n",
            "Nearest neighbors:\n",
            "  Ancient: 0.1190\n",
            "  only: 0.1174\n",
            "  Mad: 0.1087\n",
            "  flying: 0.1071\n",
            "  растения: 0.1071\n",
            "[MASK] predictions:\n",
            "  inconnu\n",
            "  蹦\n",
            "  beteiligt\n",
            "  present\n",
            "  proche\n",
            "\n",
            "Processing 'exercise' (expected: 'exercice')\n",
            "Nearest neighbors:\n",
            "  Flying: 0.1421\n",
            "  flying: 0.1317\n",
            "  exercise: 0.1310\n",
            "  сите: 0.1305\n",
            "  Ancient: 0.1275\n",
            "[MASK] predictions:\n",
            "  蹦\n",
            "  beteiligt\n",
            "  present\n",
            "  anglais\n",
            "  traduit\n",
            "\n",
            "Processing 'gender' (expected: 'genre')\n",
            "Nearest neighbors:\n",
            "  Ancient: 0.1283\n",
            "  嶽: 0.1126\n",
            "  only: 0.1087\n",
            "  kundi: 0.1061\n",
            "  either: 0.1055\n",
            "[MASK] predictions:\n",
            "  inconnu\n",
            "  present\n",
            "  蹦\n",
            "  proche\n",
            "  simple\n",
            "\n",
            "Processing 'gorilla' (expected: 'gorille')\n",
            "Nearest neighbors:\n",
            "  only: 0.1397\n",
            "  marked: 0.1177\n",
            "  barruko: 0.1154\n",
            "  noong: 0.1151\n",
            "  elections: 0.1145\n",
            "[MASK] predictions:\n",
            "  inconnu\n",
            "  蹦\n",
            "  beteiligt\n",
            "  present\n",
            "  japonais\n",
            "\n",
            "Processing 'loyalty' (expected: 'loyauté')\n",
            "Nearest neighbors:\n",
            "  Ancient: 0.1228\n",
            "  only: 0.1205\n",
            "  flying: 0.1192\n",
            "  Flying: 0.1162\n",
            "  嶽: 0.1148\n",
            "[MASK] predictions:\n",
            "  inconnu\n",
            "  蹦\n",
            "  present\n",
            "  proche\n",
            "  populaire\n",
            "\n",
            "Processing 'notation' (expected: 'notamment')\n",
            "Nearest neighbors:\n",
            "  ʸ: 0.1228\n",
            "  входит: 0.1148\n",
            "  динамикасы: 0.1146\n",
            "  越: 0.1130\n",
            "  Mad: 0.1128\n",
            "[MASK] predictions:\n",
            "  inconnu\n",
            "  蹦\n",
            "  beteiligt\n",
            "  present\n",
            "  proche\n",
            "\n",
            "Processing 'objective' (expected: 'objectif')\n",
            "Nearest neighbors:\n",
            "  flying: 0.1183\n",
            "  Flying: 0.1163\n",
            "  сих: 0.1119\n",
            "  only: 0.1083\n",
            "  нем: 0.1079\n",
            "[MASK] predictions:\n",
            "  objective\n",
            "  objectif\n",
            "  inconnu\n",
            "  simple\n",
            "  proche\n",
            "\n",
            "Processing 'oratory' (expected: 'oratoire')\n",
            "Nearest neighbors:\n",
            "  Ancient: 0.1131\n",
            "  only: 0.1114\n",
            "  止: 0.1084\n",
            "  τους: 0.1083\n",
            "  either: 0.1082\n",
            "[MASK] predictions:\n",
            "  inconnu\n",
            "  present\n",
            "  蹦\n",
            "  beteiligt\n",
            "  latin\n",
            "\n",
            "Processing 'particle' (expected: 'particule')\n",
            "Nearest neighbors:\n",
            "  Flying: 0.1312\n",
            "  flying: 0.1244\n",
            "  ʸ: 0.1224\n",
            "  Force: 0.1165\n",
            "  wider: 0.1104\n",
            "[MASK] predictions:\n",
            "  present\n",
            "  inconnu\n",
            "  beteiligt\n",
            "  proche\n",
            "  蹦\n",
            "\n",
            "Processing 'quarter' (expected: 'quartier')\n",
            "Nearest neighbors:\n",
            "  marked: 0.1189\n",
            "  only: 0.1165\n",
            "  Ancient: 0.1158\n",
            "  達: 0.1150\n",
            "  τους: 0.1073\n",
            "[MASK] predictions:\n",
            "  courant\n",
            "  inconnu\n",
            "  present\n",
            "  proche\n",
            "  beteiligt\n",
            "\n",
            "Processing 'september' (expected: 'septembre')\n",
            "Nearest neighbors:\n",
            "  insects: 0.1109\n",
            "  flying: 0.1066\n",
            "  Ancient: 0.1064\n",
            "  only: 0.1051\n",
            "  cunoscute: 0.1029\n",
            "[MASK] predictions:\n",
            "  inconnu\n",
            "  beteiligt\n",
            "  latin\n",
            "  蹦\n",
            "  anglais\n",
            "\n",
            "Processing 'skeleton' (expected: 'squelette')\n",
            "Nearest neighbors:\n",
            "  Ancient: 0.1209\n",
            "  only: 0.1174\n",
            "  входит: 0.1143\n",
            "  either: 0.1070\n",
            "  Mad: 0.1064\n",
            "[MASK] predictions:\n",
            "  蹦\n",
            "  inconnu\n",
            "  beteiligt\n",
            "  present\n",
            "  simple\n",
            "\n",
            "Processing 'traditionally' (expected: 'traditionnellement')\n",
            "Nearest neighbors:\n",
            "  Ancient: 0.1353\n",
            "  растения: 0.1202\n",
            "  elections: 0.1184\n",
            "  only: 0.1146\n",
            "  των: 0.1115\n",
            "[MASK] predictions:\n",
            "  inconnu\n",
            "  proche\n",
            "  beteiligt\n",
            "  present\n",
            "  populaire\n",
            "\n",
            "Processing 'voice' (expected: 'voix')\n",
            "Nearest neighbors:\n",
            "  неё: 0.1275\n",
            "  flying: 0.1248\n",
            "  Ancient: 0.1245\n",
            "  only: 0.1236\n",
            "  Force: 0.1195\n",
            "[MASK] predictions:\n",
            "  beteiligt\n",
            "  inconnu\n",
            "  present\n",
            "  蹦\n",
            "  parle\n",
            "\n",
            "Processing 'west' (expected: 'ouest')\n",
            "Nearest neighbors:\n",
            "  flying: 0.1344\n",
            "  tawo: 0.1302\n",
            "  cunoscute: 0.1286\n",
            "  Flying: 0.1266\n",
            "  marked: 0.1260\n",
            "[MASK] predictions:\n",
            "  proche\n",
            "  inconnu\n",
            "  present\n",
            "  issu\n",
            "  courant\n",
            "\n",
            "Processing 'wine' (expected: 'vin')\n",
            "Nearest neighbors:\n",
            "  only: 0.1328\n",
            "  входит: 0.1201\n",
            "  Ancient: 0.1198\n",
            "  製: 0.1152\n",
            "  των: 0.1135\n",
            "[MASK] predictions:\n",
            "  inconnu\n",
            "  blanc\n",
            "  issu\n",
            "  noir\n",
            "  latin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(word_pairs, tokenizer, embedding_model, mlm_model, vocab_words, vocab_embeddings, top_k=5):\n",
        "    \"\"\"\n",
        "    Evaluate the Nearest Neighbor and [MASK] approaches on the given word pairs.\n",
        "    Returns the accuracy for each method.\n",
        "    \"\"\"\n",
        "    nn_correct = 0\n",
        "    mask_correct = 0\n",
        "\n",
        "    for word_en, word_fr in word_pairs:\n",
        "        print(f\"\\nProcessing '{word_en}' (expected: '{word_fr}')\")\n",
        "\n",
        "        # Nearest Neighbor Approach\n",
        "        nearest_neighbors = find_nearest_neighbors_direct(word_en, tokenizer, embedding_model, vocab_embeddings, vocab_words, top_k)\n",
        "        nn_predictions = [token for token, _ in nearest_neighbors]\n",
        "\n",
        "        # [MASK] Approach\n",
        "        mask_predictions = predict_with_mask(word_en, tokenizer, mlm_model, top_k)\n",
        "\n",
        "        # Check if the expected word is in the top_k predictions\n",
        "        if word_fr in nn_predictions:\n",
        "            nn_correct += 1\n",
        "        if word_fr in mask_predictions:\n",
        "            mask_correct += 1\n",
        "\n",
        "        # Print results for debugging\n",
        "        print(f\"Nearest neighbors: {nn_predictions}\")\n",
        "        print(f\"[MASK] predictions: {mask_predictions}\")\n",
        "\n",
        "    # Calculate accuracy\n",
        "    total = len(word_pairs)\n",
        "    nn_accuracy = nn_correct / total * 100\n",
        "    mask_accuracy = mask_correct / total * 100\n",
        "\n",
        "    print(\"\\nEvaluation Results:\")\n",
        "    print(f\"Nearest Neighbor Accuracy: {nn_accuracy:.2f}%\")\n",
        "    print(f\"[MASK] Accuracy: {mask_accuracy:.2f}%\")\n",
        "\n",
        "    return nn_accuracy, mask_accuracy\n",
        "\n",
        "\n",
        "# Evaluate the hardcoded word pairs\n",
        "nn_accuracy, mask_accuracy = evaluate(\n",
        "    word_pairs,\n",
        "    tokenizer,\n",
        "    embedding_model,\n",
        "    mlm_model,\n",
        "    vocab_words,\n",
        "    vocab_embeddings,\n",
        "    top_k=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu-TuR_f0nva",
        "outputId": "3c0b474f-e8f5-4ebf-953e-ef8a0cbf9c40"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing 'academic' (expected: 'académique')\n",
            "Nearest neighbors: ['only', 'Mad', 'Ancient', '達', 'Flying']\n",
            "[MASK] predictions: ['inconnu', 'latin', 'scientifique', 'anglais', 'français']\n",
            "\n",
            "Processing 'administrator' (expected: 'administrateur')\n",
            "Nearest neighbors: ['only', 'شروع', 'нем', 'Bart', 'կամ']\n",
            "[MASK] predictions: ['inconnu', '蹦', 'present', 'ancien', 'simple']\n",
            "\n",
            "Processing 'algorithm' (expected: 'algorithme')\n",
            "Nearest neighbors: ['schnell', 'Ergebnis', 'Flying', 'شروع', 'wahrscheinlich']\n",
            "[MASK] predictions: ['inconnu', '蹦', 'proche', 'present', 'beteiligt']\n",
            "\n",
            "Processing 'chemical' (expected: 'chimique')\n",
            "Nearest neighbors: ['Pflanzen', 'ʸ', '浦', 'only', 'πριν']\n",
            "[MASK] predictions: ['inconnu', 'simple', 'latin', 'proche', 'courant']\n",
            "\n",
            "Processing 'delicious' (expected: 'délicieux')\n",
            "Nearest neighbors: ['Ancient', 'only', 'flying', '達', 'pur']\n",
            "[MASK] predictions: ['蹦', 'inconnu', 'simple', 'present', 'vrai']\n",
            "\n",
            "Processing 'emotion' (expected: 'émotion')\n",
            "Nearest neighbors: ['Ancient', 'only', 'Mad', 'flying', 'растения']\n",
            "[MASK] predictions: ['inconnu', '蹦', 'beteiligt', 'present', 'proche']\n",
            "\n",
            "Processing 'exercise' (expected: 'exercice')\n",
            "Nearest neighbors: ['Flying', 'flying', 'exercise', 'сите', 'Ancient']\n",
            "[MASK] predictions: ['蹦', 'beteiligt', 'present', 'anglais', 'traduit']\n",
            "\n",
            "Processing 'gender' (expected: 'genre')\n",
            "Nearest neighbors: ['Ancient', '嶽', 'only', 'kundi', 'either']\n",
            "[MASK] predictions: ['inconnu', 'present', '蹦', 'proche', 'simple']\n",
            "\n",
            "Processing 'gorilla' (expected: 'gorille')\n",
            "Nearest neighbors: ['only', 'marked', 'barruko', 'noong', 'elections']\n",
            "[MASK] predictions: ['inconnu', '蹦', 'beteiligt', 'present', 'japonais']\n",
            "\n",
            "Processing 'loyalty' (expected: 'loyauté')\n",
            "Nearest neighbors: ['Ancient', 'only', 'flying', 'Flying', '嶽']\n",
            "[MASK] predictions: ['inconnu', '蹦', 'present', 'proche', 'populaire']\n",
            "\n",
            "Processing 'notation' (expected: 'notamment')\n",
            "Nearest neighbors: ['ʸ', 'входит', 'динамикасы', '越', 'Mad']\n",
            "[MASK] predictions: ['inconnu', '蹦', 'beteiligt', 'present', 'proche']\n",
            "\n",
            "Processing 'objective' (expected: 'objectif')\n",
            "Nearest neighbors: ['flying', 'Flying', 'сих', 'only', 'нем']\n",
            "[MASK] predictions: ['objective', 'objectif', 'inconnu', 'simple', 'proche']\n",
            "\n",
            "Processing 'oratory' (expected: 'oratoire')\n",
            "Nearest neighbors: ['Ancient', 'only', '止', 'τους', 'either']\n",
            "[MASK] predictions: ['inconnu', 'present', '蹦', 'beteiligt', 'latin']\n",
            "\n",
            "Processing 'particle' (expected: 'particule')\n",
            "Nearest neighbors: ['Flying', 'flying', 'ʸ', 'Force', 'wider']\n",
            "[MASK] predictions: ['present', 'inconnu', 'beteiligt', 'proche', '蹦']\n",
            "\n",
            "Processing 'quarter' (expected: 'quartier')\n",
            "Nearest neighbors: ['marked', 'only', 'Ancient', '達', 'τους']\n",
            "[MASK] predictions: ['courant', 'inconnu', 'present', 'proche', 'beteiligt']\n",
            "\n",
            "Processing 'september' (expected: 'septembre')\n",
            "Nearest neighbors: ['insects', 'flying', 'Ancient', 'only', 'cunoscute']\n",
            "[MASK] predictions: ['inconnu', 'beteiligt', 'latin', '蹦', 'anglais']\n",
            "\n",
            "Processing 'skeleton' (expected: 'squelette')\n",
            "Nearest neighbors: ['Ancient', 'only', 'входит', 'either', 'Mad']\n",
            "[MASK] predictions: ['蹦', 'inconnu', 'beteiligt', 'present', 'simple']\n",
            "\n",
            "Processing 'traditionally' (expected: 'traditionnellement')\n",
            "Nearest neighbors: ['Ancient', 'растения', 'elections', 'only', 'των']\n",
            "[MASK] predictions: ['inconnu', 'proche', 'beteiligt', 'present', 'populaire']\n",
            "\n",
            "Processing 'voice' (expected: 'voix')\n",
            "Nearest neighbors: ['неё', 'flying', 'Ancient', 'only', 'Force']\n",
            "[MASK] predictions: ['beteiligt', 'inconnu', 'present', '蹦', 'parle']\n",
            "\n",
            "Processing 'west' (expected: 'ouest')\n",
            "Nearest neighbors: ['flying', 'tawo', 'cunoscute', 'Flying', 'marked']\n",
            "[MASK] predictions: ['proche', 'inconnu', 'present', 'issu', 'courant']\n",
            "\n",
            "Processing 'wine' (expected: 'vin')\n",
            "Nearest neighbors: ['only', 'входит', 'Ancient', '製', 'των']\n",
            "[MASK] predictions: ['inconnu', 'blanc', 'issu', 'noir', 'latin']\n",
            "\n",
            "Evaluation Results:\n",
            "Nearest Neighbor Accuracy: 0.00%\n",
            "[MASK] Accuracy: 4.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Preprocess Dataset ##"
      ],
      "metadata": {
        "id": "z9DAncAe2GtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the English-French subset of the Helsinki-NLP/europarl dataset\n",
        "dataset = load_dataset(\"Helsinki-NLP/europarl\", \"en-fr\")\n",
        "\n",
        "# Inspect the dataset\n",
        "print(dataset)\n",
        "\n",
        "# Print a few examples\n",
        "print(\"\\nSample from the training set:\")\n",
        "print(dataset[\"train\"][0])\n",
        "\n",
        "# Check the number of examples in each split\n",
        "print(\"\\nNumber of examples in each split:\")\n",
        "print({split: len(dataset[split]) for split in dataset})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9WDrIF019UD",
        "outputId": "cd71ac1a-17d6-4a4c-e846-2a9f34c967b8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['translation'],\n",
            "        num_rows: 2051014\n",
            "    })\n",
            "})\n",
            "\n",
            "Sample from the training set:\n",
            "{'translation': {'en': 'Resumption of the session', 'fr': 'Reprise de la session'}}\n",
            "\n",
            "Number of examples in each split:\n",
            "{'train': 2051014}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the dataset and select 10,000 examples\n",
        "small_dataset = dataset[\"train\"].shuffle(seed=42).select(range(10000))\n",
        "\n",
        "# Inspect the smaller dataset\n",
        "print(f\"\\nSmall dataset size: {len(small_dataset)}\")\n",
        "print(\"\\nSample from the small dataset:\")\n",
        "print(small_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDb42UQp2Oii",
        "outputId": "fc2fcf4f-e872-40f4-c619-7790aa7ef648"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Small dataset size: 10000\n",
            "\n",
            "Sample from the small dataset:\n",
            "{'translation': {'en': 'As Europeans, with our experience, our culture of peace and our economic opportunities, we too are called upon to make our contribution towards a better future for Iraq.', 'fr': \"Les Européens que nous sommes, avec leur expérience, leur culture de la paix et leurs moyens économiques, sont appelés à apporter leur contribution en faveur d'un avenir meilleur en Irak.\"}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the small dataset into 80% train and 20% temporary\n",
        "train_val_test_split = small_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "# Further split the temporary set (20%) into 10% validation and 10% test\n",
        "val_test_split = train_val_test_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
        "\n",
        "# Final splits\n",
        "train_dataset = train_val_test_split[\"train\"]\n",
        "val_dataset = val_test_split[\"train\"]\n",
        "test_dataset = val_test_split[\"test\"]\n",
        "\n",
        "# Print sizes of the splits\n",
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(val_dataset)}\")\n",
        "print(f\"Test set size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDFVLnn56L_h",
        "outputId": "73a5a709-e3d6-4b20-baf7-1d6535966b2a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 8000\n",
            "Validation set size: 1000\n",
            "Test set size: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    \"\"\"\n",
        "    Preprocess examples by tokenizing English and French text and preparing input and label tensors.\n",
        "    \"\"\"\n",
        "    # Extract English and French sentences as lists\n",
        "    inputs = [item[\"en\"] for item in examples[\"translation\"]]  # Extract \"en\" field from each item\n",
        "    targets = [item[\"fr\"] for item in examples[\"translation\"]]  # Extract \"fr\" field from each item\n",
        "\n",
        "    # Tokenize English and French sentences\n",
        "    model_inputs = tokenizer(inputs, max_length=64, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(targets, max_length=64, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # MLM labels: Add tokenized French sentences to labels\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "# Apply preprocessing to each dataset split\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "val_dataset = val_dataset.map(preprocess_function, batched=True)\n",
        "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Remove unnecessary columns (translation field)\n",
        "train_dataset = train_dataset.remove_columns([\"translation\"])\n",
        "val_dataset = val_dataset.remove_columns([\"translation\"])\n",
        "test_dataset = test_dataset.remove_columns([\"translation\"])\n",
        "\n",
        "# Set the format to PyTorch for efficient data loading\n",
        "train_dataset.set_format(\"torch\")\n",
        "val_dataset.set_format(\"torch\")\n",
        "test_dataset.set_format(\"torch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "d0745fb658e24000bb40e6f198e21d82",
            "02d5b53bf8844606be0676f42550b3e7",
            "89affbb2474642bfb4470524775d00e6",
            "835ba9c47c18404985ca51eaf20f8887",
            "1cec46f74f494f8fa26a3f314411b299",
            "37301277f0e5421aac9b251424a017cf",
            "cb08466f33e54549a89722ef0fd6cba6",
            "6ba0c7ce1db241438557ba8c9dfcc652",
            "22fa20be89f146099d5c7dafe36b0de7",
            "a9c73024e1f84985a7b31599dc642855",
            "0c4677627acb408d9b0d398de63ca7bd",
            "08635ea8e21845509261871b3a728f72",
            "40963c31c3574faab26b0ff2e872a83e",
            "8abc8fcdc60a47e6af3475fdb5e1dffe",
            "07757a53ee6b403b8de4604905175ba4",
            "b573c7b7157f44c18163cb1d837a575a",
            "82ccff5fb05248eca8ba76c8509f5314",
            "977e99dd95a64ba0961884051e230af1",
            "b880fe85695d418f84f336ad564b2f77",
            "ae1cc91a35314207807633bfce130886",
            "17b8cbbc6be14fc8bf3c8ce99b8371e8",
            "f784d9ce78954b849d8a6e7e8ce07a8d",
            "b3212b1bdc5744f4a858d0f3a20df071",
            "758b35cc9bef4f208eddfc89892b46e6",
            "6b01005ad25144dbadd26d125a2a4e9e",
            "02adbe08a35345af8d4b5bcc4facbf7f",
            "daafc10fc97b41d5af0fbc02bba9587f",
            "d239d74f55c84a839086584c5d6b3628",
            "ef80d28420054e2384b2dd50260039f7",
            "de3eb409bf424fbba7a373dde3c040da",
            "c41b7e7736f348d99a704ab7992bbbfb",
            "1e913960cea14cb8b87c2f21604bdbfc",
            "051954ffb5564331b0754359ea4854d1"
          ]
        },
        "id": "RTxjX7Vj79a6",
        "outputId": "fd904ac5-4f8c-4d22-ce19-aaed450be715"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0745fb658e24000bb40e6f198e21d82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08635ea8e21845509261871b3a728f72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3212b1bdc5744f4a858d0f3a20df071"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect a preprocessed example from the training set\n",
        "print(\"\\nSample preprocessed training example:\")\n",
        "print(train_dataset[0])\n",
        "\n",
        "# Verify dataset sizes after preprocessing\n",
        "print(f\"\\nFinal dataset sizes:\")\n",
        "print(f\"Training set: {len(train_dataset)}\")\n",
        "print(f\"Validation set: {len(val_dataset)}\")\n",
        "print(f\"Test set: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJFXPfm59JqT",
        "outputId": "de03305f-6078-4dba-c13f-3b4360360614"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample preprocessed training example:\n",
            "{'input_ids': tensor([  101, 11723, 10301,   169, 14772, 11299, 11846, 13641, 24317, 10230,\n",
            "        99402, 21422,   117, 10473,   146, 10392, 10108, 10105, 32282, 10189,\n",
            "        10105, 63711, 10108, 13246, 18322, 21422, 14819, 10472, 10347, 32296,\n",
            "          119,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([  101, 10282, 16507, 10119, 13023, 11491, 10104, 25005, 62651, 10107,\n",
            "        21535, 24407,   117, 55956, 10144, 49301,   172,   112, 57822, 10608,\n",
            "          112, 10154, 10554, 30441, 10801, 56566, 11129, 10109, 15162, 10104,\n",
            "        25005, 14375, 92036,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])}\n",
            "\n",
            "Final dataset sizes:\n",
            "Training set: 8000\n",
            "Validation set: 1000\n",
            "Test set: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetune Model ##"
      ],
      "metadata": {
        "id": "8BGx9YByADkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "import evaluate\n",
        "\n",
        "# Load accuracy metric\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "# Define metric computation function\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Computes accuracy during validation.\n",
        "    \"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "_m7n4ywIAAr8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from transformers import Trainer\n",
        "\n",
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Optuna objective function for hyperparameter tuning.\n",
        "    \"\"\"\n",
        "    # Suggest hyperparameters to tune\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 0.01, 0.3)  # Adjusted range for weight decay\n",
        "\n",
        "    # Define training arguments\n",
        "    arguments = TrainingArguments(\n",
        "        output_dir=\"/content/drive/MyDrive/Colab Notebooks/cognate_trainer\",\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        logging_steps=8,\n",
        "        num_train_epochs=5,\n",
        "        eval_strategy=\"epoch\",  # Updated from evaluation_strategy\n",
        "        save_strategy=\"epoch\",\n",
        "        learning_rate=learning_rate,\n",
        "        weight_decay=weight_decay,\n",
        "        load_best_model_at_end=True,\n",
        "        report_to=\"none\",\n",
        "        seed=224,\n",
        "    )\n",
        "\n",
        "    # Initialize the Trainer\n",
        "    trainer = Trainer(\n",
        "        model=mlm_model,  # Use the MLM model\n",
        "        args=arguments,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate on the validation dataset and return accuracy\n",
        "    eval_result = trainer.evaluate()\n",
        "    return eval_result[\"eval_accuracy\"]"
      ],
      "metadata": {
        "id": "bWWSL8L2Arwp"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Optuna study\n",
        "study = optuna.create_study(direction=\"maximize\")  # Maximize accuracy\n",
        "\n",
        "# Optimize the study\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(study.best_params)"
      ],
      "metadata": {
        "id": "mppzuBT_BLcA",
        "outputId": "b3fff35b-fd09-4c52-d2fe-6418df06594e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-27 09:24:43,352] A new study created in memory with name: no-name-c1358eaf-850e-4720-a2ed-cba2e8f7aa8d\n",
            "<ipython-input-41-8ccfcb319a61>:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='501' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 501/2500 02:32 < 10:08, 3.28 it/s, Epoch 1/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 6/63 00:00 < 00:07, 7.37 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2025-01-27 09:27:17,180] Trial 0 failed with parameters: {'learning_rate': 0.00045164970741194357, 'batch_size': 16, 'weight_decay': 0.07767016420191199} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacity of 14.75 GiB of which 331.06 MiB is free. Process 9482 has 14.42 GiB memory in use. Of the allocated memory 11.44 GiB is allocated by PyTorch, and 2.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"<ipython-input-41-8ccfcb319a61>\", line 40, in objective\n",
            "    trainer.train()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2164, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2618, in _inner_training_loop\n",
            "    self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 3049, in _maybe_log_save_evaluate\n",
            "    metrics = self._evaluate(trial, ignore_keys_for_eval)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 3003, in _evaluate\n",
            "    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 4050, in evaluate\n",
            "    output = eval_loop(\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 4271, in evaluation_loop\n",
            "    all_preds.add(logits)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py\", line 322, in add\n",
            "    self.tensors = nested_concat(self.tensors, tensors, padding_index=self.padding_index)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py\", line 136, in nested_concat\n",
            "    return torch_pad_and_concatenate(tensors, new_tensors, padding_index=padding_index)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py\", line 94, in torch_pad_and_concatenate\n",
            "    return torch.cat((tensor1, tensor2), dim=0)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacity of 14.75 GiB of which 331.06 MiB is free. Process 9482 has 14.42 GiB memory in use. Of the allocated memory 11.44 GiB is allocated by PyTorch, and 2.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "[W 2025-01-27 09:27:17,188] Trial 0 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacity of 14.75 GiB of which 331.06 MiB is free. Process 9482 has 14.42 GiB memory in use. Of the allocated memory 11.44 GiB is allocated by PyTorch, and 2.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-3b9e67147dba>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Optimize the study\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Print the best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-8ccfcb319a61>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Evaluate on the validation dataset and return accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2165\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2617\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2618\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3047\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3049\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3050\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3002\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3003\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3004\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4049\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4050\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4051\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4052\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4269\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4270\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_eval_metrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4271\u001b[0;31m                     \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4273\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_nested_concat\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_nested_concat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         return type(tensors)(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Let's figure out the new shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacity of 14.75 GiB of which 331.06 MiB is free. Process 9482 has 14.42 GiB memory in use. Of the allocated memory 11.44 GiB is allocated by PyTorch, and 2.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract best hyperparameters\n",
        "best_params = study.best_params\n",
        "\n",
        "# Define training arguments with best hyperparameters\n",
        "best_arguments = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Colab Notebooks/cognate_trainer\",\n",
        "    per_device_train_batch_size=best_params[\"batch_size\"],\n",
        "    per_device_eval_batch_size=best_params[\"batch_size\"],\n",
        "    logging_steps=8,\n",
        "    num_train_epochs=5,\n",
        "    eval_strategy=\"epoch\",  # Updated from evaluation_strategy\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=best_params[\"learning_rate\"],\n",
        "    weight_decay=best_params[\"weight_decay\"],\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",\n",
        "    seed=224,\n",
        ")\n",
        "\n",
        "# Initialize the Trainer with the best configuration\n",
        "best_trainer = Trainer(\n",
        "    model=mlm_model,  # Use the correct model object\n",
        "    args=best_arguments,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,  # Pass the tokenizer\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "foKaxwLvBRK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Train the model with the best hyperparameters\n",
        "best_trainer.train()\n",
        "\n",
        "# Ensure the output directory exists before saving\n",
        "output_dir = \"/content/drive/MyDrive/Colab Notebooks/cognate_trainer_best_model\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Save the best model\n",
        "best_trainer.save_model(output_dir)"
      ],
      "metadata": {
        "id": "KkDKNfM5EiKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the fine-tuned model on the test dataset\n",
        "test_results = best_trainer.evaluate(test_dataset)\n",
        "\n",
        "print(\"\\nTest Results:\")\n",
        "print(test_results)"
      ],
      "metadata": {
        "id": "v0Ht4XRkEsN7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}